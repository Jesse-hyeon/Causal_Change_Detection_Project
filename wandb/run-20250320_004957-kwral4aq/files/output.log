
==================================================
ðŸš€ [ Running Experiment ] - Model: lstm
==================================================

--------------------------------------------------
ðŸ” Causal Discovery Method: Lasso
--------------------------------------------------
[I 2025-03-20 00:49:58,489] A new study created in memory with name: no-name-b563f78f-d0f3-471c-b649-6abffa512d22
--- TS-CV Fold 1/1 ---
Use CPU
train 1979
val 1
test 192
Epoch: 1 cost time: 1.3914906978607178
Epoch: 1, Steps: 30 | Train Loss: 0.9411864 Vali Loss: 4.4922919 Test Loss: 7.0776503
Validation loss decreased (inf --> 4.492292).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.2797520160675049
Epoch: 2, Steps: 30 | Train Loss: 0.6192936 Vali Loss: 3.4996490 Test Loss: 5.9683022
Validation loss decreased (4.492292 --> 3.499649).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.30064058303833
Epoch: 3, Steps: 30 | Train Loss: 0.5316388 Vali Loss: 3.1529562 Test Loss: 5.6003787
Validation loss decreased (3.499649 --> 3.152956).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.3440678119659424
Epoch: 4, Steps: 30 | Train Loss: 0.4864157 Vali Loss: 2.9973605 Test Loss: 5.4460388
Validation loss decreased (3.152956 --> 2.997360).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4347929954528809
Epoch: 5, Steps: 30 | Train Loss: 0.4634427 Vali Loss: 2.9208872 Test Loss: 5.3728893
Validation loss decreased (2.997360 --> 2.920887).  Saving model ...
Updating learning rate to 6.25e-06
val 1
Fold 1 validation loss: 2.9209
Average validation loss over 1 folds: 2.9209
[I 2025-03-20 00:50:07,068] Trial 0 finished with value: 2.9208872318267822 and parameters: {'d_model': 384, 'n_heads': 6, 'e_layers': 3, 'd_layers': 1, 'd_ff': 3072, 'dropout': 0.18115368215104732, 'batch_size': 64, 'activation': 'gelu'}. Best is trial 0 with value: 2.9208872318267822.
Best hyperparameters: {'d_model': 384, 'n_heads': 6, 'e_layers': 3, 'd_layers': 1, 'd_ff': 3072, 'dropout': 0.18115368215104732, 'batch_size': 64, 'activation': 'gelu'}
Final training model
Use CPU
train 2069
val 192
test 192
Epoch: 1 cost time: 1.7154638767242432
Epoch: 1, Steps: 32 | Train Loss: 1.1520105 Vali Loss: 4.4735253 Test Loss: 6.2349342
Validation loss decreased (inf --> 4.473525).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5237290859222412
Epoch: 2, Steps: 32 | Train Loss: 0.6884920 Vali Loss: 3.0697476 Test Loss: 4.8545871
Validation loss decreased (4.473525 --> 3.069748).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5420012474060059
Epoch: 3, Steps: 32 | Train Loss: 0.5722701 Vali Loss: 2.6580550 Test Loss: 4.5231925
Validation loss decreased (3.069748 --> 2.658055).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.4949493408203125
Epoch: 4, Steps: 32 | Train Loss: 0.5062648 Vali Loss: 2.4758521 Test Loss: 4.3963356
Validation loss decreased (2.658055 --> 2.475852).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5139291286468506
Epoch: 5, Steps: 32 | Train Loss: 0.4731885 Vali Loss: 2.3866970 Test Loss: 4.3379421
Validation loss decreased (2.475852 --> 2.386697).  Saving model ...
Updating learning rate to 6.25e-06
test 192
preds shape:  (192, 1, 90, 1)
trues shape:  (192, 1, 90, 1)
mape:0.2459, mae:477.89, d_stat:52.02
Final model training and testing complete.
--------------------------------------------------
ðŸ” Causal Discovery Method: PCMCI
--------------------------------------------------
[I 2025-03-20 00:50:19,124] A new study created in memory with name: no-name-87b832de-b992-4e75-b1a5-5a154d9eae8f
--- TS-CV Fold 1/1 ---
Use CPU
train 1979
val 1
test 192
Epoch: 1 cost time: 1.894773006439209
Epoch: 1, Steps: 61 | Train Loss: 0.7121982 Vali Loss: 3.1046391 Test Loss: 5.0442270
Validation loss decreased (inf --> 3.104639).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.8182320594787598
Epoch: 2, Steps: 61 | Train Loss: 0.8144136 Vali Loss: 2.6332059 Test Loss: 5.0674879
Validation loss decreased (3.104639 --> 2.633206).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.812891960144043
Epoch: 3, Steps: 61 | Train Loss: 0.5015480 Vali Loss: 2.0286343 Test Loss: 4.7126519
Validation loss decreased (2.633206 --> 2.028634).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.8095760345458984
Epoch: 4, Steps: 61 | Train Loss: 0.4036184 Vali Loss: 1.7265480 Test Loss: 4.5319902
Validation loss decreased (2.028634 --> 1.726548).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.777266263961792
Epoch: 5, Steps: 61 | Train Loss: 0.3566883 Vali Loss: 1.5726643 Test Loss: 4.4370373
Validation loss decreased (1.726548 --> 1.572664).  Saving model ...
Updating learning rate to 6.25e-06
val 1
Fold 1 validation loss: 1.5727
Average validation loss over 1 folds: 1.5727
[I 2025-03-20 00:50:29,723] Trial 0 finished with value: 1.5726642608642578 and parameters: {'d_model': 128, 'n_heads': 14, 'e_layers': 4, 'd_layers': 3, 'd_ff': 1536, 'dropout': 0.050413754243282094, 'batch_size': 32, 'activation': 'gelu'}. Best is trial 0 with value: 1.5726642608642578.
Best hyperparameters: {'d_model': 128, 'n_heads': 14, 'e_layers': 4, 'd_layers': 3, 'd_ff': 1536, 'dropout': 0.050413754243282094, 'batch_size': 32, 'activation': 'gelu'}
Final training model
Use CPU
train 2069
val 192
test 192
Epoch: 1 cost time: 1.8469882011413574
Epoch: 1, Steps: 64 | Train Loss: 0.7781433 Vali Loss: 2.9434864 Test Loss: 4.7548041
Validation loss decreased (inf --> 2.943486).  Saving model ...
Updating learning rate to 0.0001
