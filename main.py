import platform
import os

import json
import random
import pandas as pd
import numpy as np
import wandb

import torch

from src.train.optuna_code import HyperParameterTuner

### config(JSON íŒŒì¼) ë¶ˆëŸ¬ì˜¤ê¸°
if platform.system() == 'Windows':
    base_path = 'C:/Users/T-Lab_Public/PycharmProjects/Causal-Discovery'
else:
    base_path = '/Users/choeseoheon/Desktop/Causal-Discovery'

config_path = base_path + "/src/Arg/config.json"

with open(config_path, "r") as f:
    base_config = json.load(f)

### ë°ì´í„° ê´€ë ¨ ì •ë³´ ì €ì¥
raw_data = pd.read_csv(os.path.join(base_config["root_path"], base_config["data_path"]))
print("raw data columns :", len(raw_data.columns))

# ìµœì¢… ì‹¤í—˜ì— ì‚¬ìš©í•  train, test, valid ê¸¸ì´ ë°˜í™˜
# num_train_original = int(len(raw_data) * base_config["train_ratio"])
# num_test_original = int(len(raw_data) * base_config["test_ratio"])

### seed ê³ ì •
fix_seed = base_config["seed"]
random.seed(fix_seed)
torch.manual_seed(fix_seed)
np.random.seed(fix_seed)

# ğŸ”’ GPU ì—°ì‚°ë„ ê²°ì •ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì¶”ê°€ ì„¤ì •
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

### Feature set JSON ë¶ˆëŸ¬ì˜¤ê¸°
feature_json_path = os.path.join(base_path, "output", "feature_sets.json")

with open(feature_json_path, "r") as f:
    feature_sets = json.load(f)

# ì‹¤í—˜í•  ì¸ê³¼ ì¶”ë¡  ê¸°ë²• ìˆ˜ë™ ì„¤ì • (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)
# ["all", "Lasso", "PCMCI", "VARLiNGAM", "NBCB", "CBNB"]
selected_methods = ["all", "Lasso", "PCMCI", "VARLiNGAM", "NBCB", "CBNB"]
model_list = ["rnn"]
pred_len_list = [90]

if selected_methods is not None:
    causal_discovery_list = [m for m in selected_methods if m in feature_sets]
else:
    causal_discovery_list = list(feature_sets.keys())

### ìµœì¢… ì‹¤í—˜ í•¨ìˆ˜
def run_model(config):
    for pred_len in pred_len_list:
        print("\n" + "*" * 50)
        print(f"ğŸ’¥ | Forecast Horizon | - pred_len: {pred_len}")
        print("*" * 50 + "\n")
        num_test_original = pred_len
        num_train_original = int(len(raw_data) - num_test_original)

        base_config["num_train_original"] = num_train_original
        for model_name in model_list:
            config["model"] = model_name
            print("\n" + "=" * 50)
            print(f"ğŸš€ [ Running Experiment ] - Model: {model_name}")
            print("=" * 50 + "\n")

            for cd_name in causal_discovery_list:
                print("-" * 50)
                print(f"ğŸ” Causal Discovery Method: {cd_name}")
                print("-" * 50)

                config["feature_set"] = feature_sets[cd_name]
                print("len_feature set",len(config["feature_set"]))
                print(config["feature_set"])

                # âœ… wandb ê¸°ë¡ ì¡°ê±´ ì¶”ê°€
                if config.get("use_wandb", False):
                    wandb.init(
                        project=config.get("wandb_project", "default_project"),
                        name=f"{model_name}_{cd_name}",
                        config=config
                    )

                if config["model"] in config["former_model"]:
                    len_in_former = len(config["feature_set"]) - 1
                    config["enc_in"] = len_in_former
                    config["dec_in"] = len_in_former
                else:
                    len_in_rnn = len(config["feature_set"]) - 1 + 3
                    config["enc_in"] = len_in_rnn
                    config["dec_in"] = len_in_rnn

                # ğŸ” Grid vs Random ë¶„ê¸°
                if config.get("use_randomsearch", False):
                    param_ranges = {
                        "d_model": {"type": "int", "low": 128, "high": 1024, "step": 128},
                        "n_heads": {"type": "int", "low": 2, "high": 16, "step": 2},
                        "e_layers": {"type": "int", "low": 1, "high": 4},
                        "d_layers": {"type": "int", "low": 1, "high": 3},
                        "d_ff": {"type": "int", "low": 512, "high": 4096, "step": 512},
                        "dropout": {"type": "float", "low": 0.0, "high": 0.5},
                        "activation": {"type": "categorical", "choices": ["relu", "gelu"]},
                        "batch_size": {"type": "categorical", "choices": [16, 32, 64]},
                        "learning_rate": {"type": "float", "low": 1e-5, "high": 1e-3, "log": True}
                    }
                    n_trials = config.get("n_trials", 2)
                else:
                    param_ranges = {
                        "d_model": [512, 640, 896],
                        "n_heads": [2, 4, 8],
                        "activation": ["relu", "gelu"]
                    }
                    n_trials = None  # Grid searchëŠ” ì¡°í•© ìˆ˜ì— ë”°ë¼ ìë™ ê²°ì •ë¨

                tuner = HyperParameterTuner(config, param_ranges, n_splits=2, n_trials=n_trials or 1)
                study = tuner.run_study()
                if study.best_trial is not None:
                    tuner.best_params = study.best_trial.params
                    tuner.train_final_model()

                # í˜„ì¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥
                if config.get("use_wandb", False):
                    wandb.config.update({"best_hyperparams": tuner.best_params})

                tuner.train_final_model()

                if config.get("use_wandb", False):
                    wandb.finish()

if __name__ == '__main__':
    # run_causal_discovery(base_config)
    base_config["wandb_project"] = "ê·¸ë˜í”„ ì´ì˜ê²Œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸"
    run_model(base_config)