import numpy as np
import pandas as pd

from tigramite import data_processing as pp
from tigramite.independence_tests.parcorr import ParCorr
from tigramite.pcmci import PCMCI
from lingam import VARLiNGAM

class nbcb_model:
    def __init__(self,
                 data: pd.DataFrame,
                 tau_max: int = 3,
                 sig_level: float = 0.05,
                 threshold: float = 0.01,
                 linear: bool = True):

        self.data = data
        self.tau_max = tau_max
        self.sig_level = sig_level
        self.threshold = threshold
        self.linear = linear

        self.target_var = "Com_Gold"
        self.window_causal_graph_dict = {self.target_var: []}

    def _noise_based(self):
        print("=== [NBCBw] Noise-Based Step: VarLiNGAM ===")
        var_names = list(self.data.columns)
        model = VARLiNGAM(lags=self.tau_max, criterion="HQIC", prune=False)
        model.fit(self.data.values)

        adjacency_mats = model.adjacency_matrices_
        n_vars = len(var_names)
        target_idx = var_names.index(self.target_var)

        for lag_idx, mat in enumerate(adjacency_mats, start=1):
            for j in range(n_vars):
                if j == target_idx:
                    continue
                coef = mat[target_idx, j]
                if abs(coef) > self.threshold:
                    cause_name = var_names[j]
                    self.window_causal_graph_dict[self.target_var].append((cause_name, -lag_idx))

    def _constraint_based(self):
        print("=== [NBCBw] Constraint-Based Step: PCMCI ===")

        nb_candidates = set(self.window_causal_graph_dict[self.target_var])
        var_names = list(self.data.columns)

        # ëŒ€ìƒ ë³€ìˆ˜ + í›„ë³´ ì›ì¸ë§Œ í•„í„°ë§
        used_vars = [self.target_var] + [v for (v, _) in nb_candidates if v in var_names]
        filtered_data = self.data[used_vars]

        print("=== [DEBUG] í•„í„°ë§ëœ ë³€ìˆ˜ ëª©ë¡ ===")
        print(used_vars)

        dataframe = pp.DataFrame(
            data=filtered_data.values,
            var_names=used_vars
        )
        cond_ind_test = ParCorr(significance='analytic')
        pcmci = PCMCI(
            dataframe=dataframe,
            cond_ind_test=cond_ind_test,
            verbosity=1
        )

        results = pcmci.run_pcmci(
            tau_min=0,
            tau_max=self.tau_max,
            pc_alpha=self.sig_level
        )

        p_matrix = results["p_matrix"]
        target_idx = used_vars.index(self.target_var)

        confirmed_causal_graph_dict = {self.target_var: []}

        for (cause_name, lag_val) in nb_candidates:
            if cause_name not in used_vars:
                continue
            j = used_vars.index(cause_name)
            tau = -lag_val

            # ì—ëŸ¬ ë°©ì§€
            if tau >= p_matrix.shape[2]:
                print(f"[âš  ê²½ê³ ] tau={tau}ê°€ p_matrixì— ì—†ìŒ. ë¬´ì‹œë¨.")
                continue

            pval = p_matrix[target_idx, j, tau]

            if pval < self.sig_level:
                confirmed_causal_graph_dict[self.target_var].append((cause_name, lag_val))
                print(f"[âœ“ CB í†µê³¼] {cause_name} (lag {lag_val}) â†’ {self.target_var} | p={pval:.5f}")
            else:
                print(f"[âœ— CB íƒˆë½] {cause_name} (lag {lag_val}) â†’ {self.target_var} | p={pval:.5f}")

        self.window_causal_graph_dict = confirmed_causal_graph_dict

        print("\n=== [CB] Final window_causal_graph_dict (filtered) ===")
        print(f"{self.target_var}: {self.window_causal_graph_dict[self.target_var]}")

    def run(self):
        self._noise_based()
        self._constraint_based()

        com_gold_causes = [cause for (cause, lag) in self.window_causal_graph_dict[self.target_var]]
        com_gold_causes = list(dict.fromkeys(com_gold_causes))

        return self.window_causal_graph_dict, com_gold_causes

class cbnb_model:
    def __init__(self,
                 data: pd.DataFrame,
                 tau_max: int = 3,
                 sig_level: float = 0.1,
                 threshold: float = 0.01,
                 linear: bool = True):

        self.data = data
        self.tau_max = tau_max
        self.sig_level = sig_level
        self.threshold = threshold
        self.linear = linear

        self.target_var = "Com_Gold"
        self.window_causal_graph_dict = {self.target_var: []}

    def _constraint_based(self):
        print("=== [CBNB] Constraint-Based Step: PCMCI ===")
        var_names = list(self.data.columns)
        dataframe = pp.DataFrame(data=self.data.values, var_names=var_names)
        cond_ind_test = ParCorr(significance='analytic')

        pcmci = PCMCI(
            dataframe=dataframe,
            cond_ind_test=cond_ind_test,
            verbosity=1
        )

        results = pcmci.run_pcmci(
            tau_min=0,
            tau_max=self.tau_max,
            pc_alpha=self.sig_level
        )

        p_matrix = results["p_matrix"]
        target_idx = var_names.index(self.target_var)

        cb_candidates = []

        for j in range(len(var_names)):
            if j == target_idx:
                continue
            for tau in range(self.tau_max + 1):
                pval = p_matrix[j, target_idx, tau]

                if pval < self.sig_level:
                    cause_name = var_names[j]
                    lag_val = -tau
                    cb_candidates.append((cause_name, lag_val))
                    print(f"[âœ“ CB í›„ë³´] {cause_name} (lag {lag_val}) â†’ {self.target_var} | p={pval:.5f}")

        self.window_causal_graph_dict[self.target_var] = cb_candidates

    def _noise_based(self):
        print("\n=== [CBNB] Noise-Based Step: VarLiNGAM (í›„ë³´ ê²€ì¦) ===")
        var_names = list(self.data.columns)

        # ğŸ”§ ìˆ˜ì •ëœ ë¶€ë¶„: criterion=Noneìœ¼ë¡œ ì„¤ì •
        model = VARLiNGAM(lags=self.tau_max, criterion="HQIC", prune=False)
        model.fit(self.data.values)
        adjacency_mats = model.adjacency_matrices_

        actual_tau_max = len(adjacency_mats)
        print(f"[DEBUG] VarLiNGAM ì¶”ì •ëœ ì‹œì°¨ ìˆ˜ (ê°•ì œ ì‚¬ìš©): {actual_tau_max}")

        target_idx = var_names.index(self.target_var)
        cb_candidates = self.window_causal_graph_dict[self.target_var]
        final_result = []

        for (cause_name, lag_val) in cb_candidates:
            cause_idx = var_names.index(cause_name)
            tau = -lag_val

            # ìœ íš¨ì„± ê²€ì‚¬
            if tau <= 0 or tau > actual_tau_max:
                print(f"[ê±´ë„ˆëœ€] Invalid tau={tau} for {cause_name} (lag {lag_val}) | ì„¤ì •ëœ tau_max={self.tau_max}, ì‹¤ì œ={actual_tau_max}")
                continue

            coef = adjacency_mats[tau - 1][target_idx, cause_idx]
            print(f"[ê³„ìˆ˜ í™•ì¸] {cause_name} (lag {lag_val}) â†’ {self.target_var} | coef={coef:.5f}")

            if abs(coef) > self.threshold:
                final_result.append((cause_name, lag_val))
                print(f"[âœ“ NB í†µê³¼] {cause_name} (lag {lag_val}) â†’ {self.target_var} | coef={coef:.5f}")
            else:
                print(f"[âœ— NB íƒˆë½] {cause_name} (lag {lag_val}) â†’ {self.target_var} | coef={coef:.5f}")

        self.window_causal_graph_dict[self.target_var] = final_result

        print("\n=== [CBNB] ìµœì¢… window_causal_graph_dict ===")
        print(f"{self.target_var}: {self.window_causal_graph_dict[self.target_var]}")

    def run(self):
        self._constraint_based()
        self._noise_based()

        com_gold_causes = [cause for (cause, lag) in self.window_causal_graph_dict[self.target_var]]
        com_gold_causes = list(dict.fromkeys(com_gold_causes))

        return self.window_causal_graph_dict, com_gold_causes
