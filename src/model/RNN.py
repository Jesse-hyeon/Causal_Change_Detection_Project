import torch
import torch.nn as nn

class rnn_model(nn.Module):
    def __init__(self, config):
        super(rnn_model, self).__init__()

        self.num_classes = config["c_out"]
        self.num_layers = config["num_layers"]
        self.input_size = config["enc_in"]
        self.hidden_size = config["hidden_size"]
        self.seq_length = config["seq_len"]
        self.pred_len = config["pred_len"]

        # ğŸ”µ RNN ë„¤íŠ¸ì›Œí¬ ì •ì˜
        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size,
                          num_layers=self.num_layers, batch_first=True, nonlinearity='tanh')

        # ğŸ”µ ìµœì¢… ì¶œë ¥ ë ˆì´ì–´
        self.fc = nn.Linear(self.hidden_size, self.num_classes)

    def forward(self, x):
        batch_size = x.size(0)

        # ğŸ”µ ì´ˆê¸° hidden state ì •ì˜ (RNNì€ cell state ì—†ìŒ)
        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)

        # ğŸ”µ RNN ì‹¤í–‰
        rnn_out, _ = self.rnn(x, h_0)  # (batch_size, seq_len, hidden_size)

        # ğŸ”µ ë§ˆì§€ë§‰ pred_lenë§Œ ì„ íƒ
        rnn_out = rnn_out[:, -self.pred_len:, :]  # (batch_size, pred_len, hidden_size)

        # ğŸ”µ ì˜ˆì¸¡ê°’ ê³„ì‚°
        output = self.fc(rnn_out)  # (batch_size, pred_len, num_classes)

        return output